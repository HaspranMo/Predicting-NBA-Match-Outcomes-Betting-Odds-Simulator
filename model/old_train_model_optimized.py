
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, log_loss, roc_auc_score
from xgboost import XGBClassifier
import joblib

# è¯»å–æ•°æ®
df = pd.read_csv("data/regular_season_totals_2010_2024.csv")

# æ„é€ æ–°ç‰¹å¾
df['FG%'] = df['FGM'] / df['FGA']
df['3P%'] = df['3PM'] / df['3PA']

# æ„é€  rolling å¹³å‡å€¼ï¼ˆæ¯é˜Ÿè¿‡å» 5 åœºçš„å¹³å‡è¡¨ç°ï¼‰
rolling_stats = ['PTS', 'REB', 'AST', 'STL', 'TOV', 'FG%', '3P%']
for stat in rolling_stats:
    df[f"{stat}_rolling"] = df.groupby("Team")[stat].transform(lambda x: x.shift(1).rolling(window=5, min_periods=1).mean())

# åˆ›å»ºæ¯”èµ›è®°å½•ï¼ˆä¸»åœºé˜Ÿ vs å®¢åœºé˜Ÿï¼‰
games = df[df['Home'] == 1].copy()
games = games.rename(columns={col: f"{col}_home" for col in df.columns if col not in ['Season', 'Team', 'Opponent']})

away_df = df[df['Home'] == 0].copy()
away_df = away_df.rename(columns={col: f"{col}_away" for col in df.columns if col not in ['Season', 'Team', 'Opponent']})

matchup_stats = pd.merge(
    games,
    away_df,
    left_on=['Season', 'Team_home', 'Opponent_home'],
    right_on=['Season', 'Opponent_away', 'Team_away'],
    suffixes=('_home', '_away')
)

# æ·»åŠ ç‰¹å¾å·®å€¼ï¼ˆä¸»é˜Ÿå‡å®¢é˜Ÿï¼‰
for stat in rolling_stats:
    matchup_stats[f"{stat}_diff_rolling"] = matchup_stats[f"{stat}_home_rolling"] - matchup_stats[f"{stat}_away_rolling"]

# æ„é€ æ ‡ç­¾å˜é‡ï¼šä¸»é˜Ÿæ˜¯å¦èµ¢äº†
matchup_stats['home_win'] = (matchup_stats['PTS_home'] > matchup_stats['PTS_away']).astype(int)

# å®šä¹‰è®­ç»ƒç”¨çš„ç‰¹å¾åˆ—
feature_columns = [f"{stat}_diff_rolling" for stat in rolling_stats]
X = matchup_stats[feature_columns]
y = matchup_stats['home_win']

# åˆ†è®­ç»ƒæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)

# æ„å»º XGBoost æ¨¡å‹ç®¡é“
pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('xgb', XGBClassifier(n_estimators=100, max_depth=4, use_label_encoder=False, eval_metric='logloss'))
])

pipe.fit(X_train, y_train)

# ä¿å­˜æ¨¡å‹
joblib.dump(pipe, 'model/xgb_pipeline.pkl')

# æ¨¡å‹è¯„ä¼°
y_pred = pipe.predict(X_test)
y_prob = pipe.predict_proba(X_test)[:, 1]

print("ğŸ“Š Evaluation on Test Set:")
print(f"Accuracy       : {accuracy_score(y_test, y_pred):.4f}")
print(f"Log Loss       : {log_loss(y_test, y_prob):.4f}")
print(f"ROC AUC Score  : {roc_auc_score(y_test, y_prob):.4f}")
